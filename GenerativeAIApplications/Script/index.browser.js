!function(e,t){"object"==typeof exports&&"object"==typeof module?module.exports=t(require("onnxruntime-web")):"function"==typeof define&&define.amd?define(["onnxruntime-web"],t):"object"==typeof exports?exports.vad=t(require("onnxruntime-web")):e.vad=t(e.ort)}(self,(e=>(()=>{"use strict";var t={656:t=>{t.exports=e}},s={};function i(e){var r=s[e];if(void 0!==r)return r.exports;var o=s[e]={exports:{}};return t[e](o,o.exports,i),o.exports}i.d=(e,t)=>{for(var s in t)i.o(t,s)&&!i.o(e,s)&&Object.defineProperty(e,s,{enumerable:!0,get:t[s]})},i.g=function(){if("object"==typeof globalThis)return globalThis;try{return this||new Function("return this")()}catch(e){if("object"==typeof window)return window}}(),i.o=(e,t)=>Object.prototype.hasOwnProperty.call(e,t),i.r=e=>{"undefined"!=typeof Symbol&&Symbol.toStringTag&&Object.defineProperty(e,Symbol.toStringTag,{value:"Module"}),Object.defineProperty(e,"__esModule",{value:!0})},(()=>{var e;i.g.importScripts&&(e=i.g.location+"");var t=i.g.document;if(!e&&t&&(t.currentScript&&(e=t.currentScript.src),!e)){var s=t.getElementsByTagName("script");s.length&&(e=s[s.length-1].src)}if(!e)throw new Error("Automatic publicPath is not supported in this browser");e=e.replace(/#.*$/,"").replace(/\?.*$/,"").replace(/\/[^\/]+$/,"/"),i.p=e})();var r={};return(()=>{function e(e,t,s){for(var i=0;i<s.length;i++,t+=4)e.setFloat32(t,s[i],!0)}function t(e,t,s){for(var i=0;i<s.length;i++,t+=2){var r=Math.max(-1,Math.min(1,s[i]));e.setInt16(t,r<0?32768*r:32767*r,!0)}}function s(e,t,s){for(var i=0;i<s.length;i++)e.setUint8(t+i,s.charCodeAt(i))}let o;i.r(r),i.d(r,{AudioNodeVAD:()=>P,FrameProcessor:()=>l,Message:()=>o,MicVAD:()=>T,NonRealTimeVAD:()=>y,utils:()=>D}),function(e){e.AudioFrame="AUDIO_FRAME",e.SpeechStart="SPEECH_START",e.VADMisfire="VAD_MISFIRE",e.SpeechEnd="SPEECH_END"}(o||(o={}));const n="[VAD]",a=["error","debug","warn"].reduce(((e,t)=>(e[t]=function(e){return function(){for(var t=arguments.length,s=new Array(t),i=0;i<t;i++)s[i]=arguments[i];console[e](n,...s)}}(t),e)),{});function h(e,t,s){return t in e?Object.defineProperty(e,t,{value:s,enumerable:!0,configurable:!0,writable:!0}):e[t]=s,e}const c=[512,1024,1536],p={positiveSpeechThreshold:.5,negativeSpeechThreshold:.35,preSpeechPadFrames:1,redemptionFrames:8,frameSamples:1536,minSpeechFrames:3};function u(e){c.includes(e.frameSamples)||a.warn("You are using an unusual frame size"),(e.positiveSpeechThreshold<0||e.negativeSpeechThreshold>1)&&a.error("postiveSpeechThreshold should be a number between 0 and 1"),(e.negativeSpeechThreshold<0||e.negativeSpeechThreshold>e.positiveSpeechThreshold)&&a.error("negativeSpeechThreshold should be between 0 and postiveSpeechThreshold"),e.preSpeechPadFrames<0&&a.error("preSpeechPadFrames should be positive"),e.redemptionFrames<0&&a.error("preSpeechPadFrames should be positive")}const d=e=>{const t=e.reduce(((e,t)=>(e.push(e.at(-1)+t.length),e)),[0]),s=new Float32Array(t.at(-1));return e.forEach(((e,i)=>{const r=t[i];s.set(e,r)})),s};class l{constructor(e,t,s){h(this,"speaking",!1),h(this,"redemptionCounter",0),h(this,"active",!1),h(this,"reset",(()=>{this.speaking=!1,this.audioBuffer=[],this.modelResetFunc(),this.redemptionCounter=0})),h(this,"pause",(()=>{this.active=!1,this.reset()})),h(this,"resume",(()=>{this.active=!0})),h(this,"endSegment",(()=>{const e=this.audioBuffer;this.audioBuffer=[];const t=this.speaking;this.reset();const s=e.reduce(((e,t)=>e+ +t.isSpeech),0);if(t){if(s>=this.options.minSpeechFrames){const t=d(e.map((e=>e.frame)));return{msg:o.SpeechEnd,audio:t}}return{msg:o.VADMisfire}}return{}})),h(this,"process",(async e=>{if(!this.active)return{};const t=await this.modelProcessFunc(e);if(this.audioBuffer.push({frame:e,isSpeech:t.isSpeech>=this.options.positiveSpeechThreshold}),t.isSpeech>=this.options.positiveSpeechThreshold&&this.redemptionCounter&&(this.redemptionCounter=0),t.isSpeech>=this.options.positiveSpeechThreshold&&!this.speaking)return this.speaking=!0,{probs:t,msg:o.SpeechStart};if(t.isSpeech<this.options.negativeSpeechThreshold&&this.speaking&&++this.redemptionCounter>=this.options.redemptionFrames){this.redemptionCounter=0,this.speaking=!1;const e=this.audioBuffer;if(this.audioBuffer=[],e.reduce(((e,t)=>e+ +t.isSpeech),0)>=this.options.minSpeechFrames){const s=d(e.map((e=>e.frame)));return{probs:t,msg:o.SpeechEnd,audio:s}}return{probs:t,msg:o.VADMisfire}}if(!this.speaking)for(;this.audioBuffer.length>this.options.preSpeechPadFrames;)this.audioBuffer.shift();return{probs:t}})),this.modelProcessFunc=e,this.modelResetFunc=t,this.options=s,this.audioBuffer=[],this.reset()}}const m=i.p+"568bf886c02ac597add4.onnx";function f(e,t,s){return t in e?Object.defineProperty(e,t,{value:s,enumerable:!0,configurable:!0,writable:!0}):e[t]=s,e}let S;S=i(656);class g{constructor(){f(this,"init",(async()=>{a.debug("initializing vad");const e=await fetch(m).then((e=>e.arrayBuffer()));this._session=await S.InferenceSession.create(e),this._sr=new S.Tensor("int64",[16000n]),this.reset_state(),a.debug("vad is initialized")})),f(this,"reset_state",(()=>{const e=Array(128).fill(0);this._h=new S.Tensor("float32",e,[2,1,64]),this._c=new S.Tensor("float32",e,[2,1,64])})),f(this,"process",(async e=>{const t={input:new S.Tensor("float32",e,[1,e.length]),h:this._h,c:this._c,sr:this._sr},s=await this._session.run(t);this._h=s.hn,this._c=s.cn;const[i]=s.output.data;return{notSpeech:1-i,isSpeech:i}}))}}f(g,"new",(async()=>{const e=new g;return await e.init(),e}));class v{constructor(e){var t,s;s=e=>{const t=[];for(const t of e)this.inputBuffer.push(t);for(;this.inputBuffer.length*this.options.targetSampleRate/this.options.nativeSampleRate>this.options.targetFrameSize;){const e=new Float32Array(this.options.targetFrameSize);let s=0,i=0;for(;s<this.options.targetFrameSize;){let t=0,r=0;for(;i<Math.min(this.inputBuffer.length,(s+1)*this.options.nativeSampleRate/this.options.targetSampleRate);)t+=this.inputBuffer[i],r++,i++;e[s]=t/r,s++}this.inputBuffer=this.inputBuffer.slice(i),t.push(e)}return t},(t="process")in this?Object.defineProperty(this,t,{value:s,enumerable:!0,configurable:!0,writable:!0}):this[t]=s,this.options=e,e.nativeSampleRate<16e3&&a.error("nativeSampleRate is too low. Should have 16000 = targetSampleRate <= nativeSampleRate"),this.inputBuffer=[]}}function w(e,t,s){return t in e?Object.defineProperty(e,t,{value:s,enumerable:!0,configurable:!0,writable:!0}):e[t]=s,e}const b={...p};class y{static async new(){const e=new y({...b,...arguments.length>0&&void 0!==arguments[0]?arguments[0]:{}});return await e.init(),e}constructor(e){w(this,"init",(async()=>{const e=await g.new();this.frameProcessor=new l(e.process,e.reset_state,{frameSamples:this.options.frameSamples,positiveSpeechThreshold:this.options.positiveSpeechThreshold,negativeSpeechThreshold:this.options.negativeSpeechThreshold,redemptionFrames:this.options.redemptionFrames,preSpeechPadFrames:this.options.preSpeechPadFrames,minSpeechFrames:this.options.minSpeechFrames}),this.frameProcessor.resume()})),w(this,"run",(async function*(e,t){const s={nativeSampleRate:t,targetSampleRate:16e3,targetFrameSize:this.options.frameSamples},i=new v(s).process(e);let r,n;for(const e of[...Array(i.length)].keys()){const t=i[e],{msg:s,audio:a}=await this.frameProcessor.process(t);switch(s){case o.SpeechStart:r=e*this.options.frameSamples/16;break;case o.SpeechEnd:n=(e+1)*this.options.frameSamples/16,yield{audio:a,start:r,end:n}}}const{msg:a,audio:h}=this.frameProcessor.endSegment();a==o.SpeechEnd&&(yield{audio:h,start:r,end:i.length*this.options.frameSamples/16})})),this.options=e,u(e)}}function F(e,t,s){return t in e?Object.defineProperty(e,t,{value:s,enumerable:!0,configurable:!0,writable:!0}):e[t]=s,e}const A={...p,onFrameProcessed:e=>{},onVADMisfire:()=>{a.debug("VAD misfire")},onSpeechStart:()=>{a.debug("Detected speech start")},onSpeechEnd:()=>{a.debug("Detected speech end")}};class T{static async new(){let e=arguments.length>0&&void 0!==arguments[0]?arguments[0]:{};const t=new T({...A,...e});return await t.init(),t}constructor(e){F(this,"listening",!1),F(this,"init",(async()=>{this.stream=await navigator.mediaDevices.getUserMedia({audio:{...this.options.additionalAudioConstraints,channelCount:1,echoCancellation:!0,autoGainControl:!0,noiseSuppression:!0}}),this.audioContext=new AudioContext;const e=new MediaStreamAudioSourceNode(this.audioContext,{mediaStream:this.stream});this.audioNodeVAD=await P.new(this.audioContext,this.options),this.audioNodeVAD.receive(e)})),F(this,"pause",(()=>{this.audioNodeVAD.pause(),this.listening=!1})),F(this,"start",(()=>{this.audioNodeVAD.start(),this.listening=!0})),this.options=e,u(e)}}class P{static async new(e){let t=arguments.length>1&&void 0!==arguments[1]?arguments[1]:{};const s=new P(e,{...A,...t});return await s.init(),s}constructor(e,t){F(this,"pause",(()=>{this.frameProcessor.pause()})),F(this,"start",(()=>{this.frameProcessor.resume()})),F(this,"receive",(e=>{e.connect(this.entryNode)})),F(this,"processFrame",(async e=>{const{probs:t,msg:s,audio:i}=await this.frameProcessor.process(e);switch(void 0!==t&&this.options.onFrameProcessed(t),s){case o.SpeechStart:this.options.onSpeechStart();break;case o.VADMisfire:this.options.onVADMisfire();break;case o.SpeechEnd:this.options.onSpeechEnd(i)}})),F(this,"init",(async()=>{const e=i.p+"vad.worklet.js";await this.ctx.audioWorklet.addModule(e);const t=new AudioWorkletNode(this.ctx,"vad-helper-worklet",{processorOptions:{frameSamples:this.options.frameSamples}});this.entryNode=t;const s=await g.new();this.frameProcessor=new l(s.process,s.reset_state,{frameSamples:this.options.frameSamples,positiveSpeechThreshold:this.options.positiveSpeechThreshold,negativeSpeechThreshold:this.options.negativeSpeechThreshold,redemptionFrames:this.options.redemptionFrames,preSpeechPadFrames:this.options.preSpeechPadFrames,minSpeechFrames:this.options.minSpeechFrames}),t.port.onmessage=async e=>{var t;if((null===(t=e.data)||void 0===t?void 0:t.message)===o.AudioFrame){const t=e.data.data,s=new Float32Array(t);await this.processFrame(s)}}})),this.ctx=e,this.options=t,u(t)}}const D={minFramesForTargetMS:function(e,t){let s=arguments.length>2&&void 0!==arguments[2]?arguments[2]:16e3;return Math.ceil(e*s/1e3/t)},arrayBufferToBase64:function(e){for(var t="",s=new Uint8Array(e),i=s.byteLength,r=0;r<i;r++)t+=String.fromCharCode(s[r]);return btoa(t)},audioFileToArray:async function(e){const t=new OfflineAudioContext(1,1,44100),s=new FileReader;let i=null;if(await new Promise((r=>{s.addEventListener("loadend",(e=>{const o=s.result;t.decodeAudioData(o,(e=>{i=e,t.startRendering().then((e=>{console.log("Rendering completed successfully"),r()})).catch((e=>{console.error(`Rendering failed: ${e}`)}))}),(e=>{console.log(`Error with decoding audio data: ${e}`)}))})),s.readAsArrayBuffer(e)})),null===i)throw Error("some shit");let r=i,o=new Float32Array(r.length);for(let e=0;e<r.length;e++)for(let t=0;t<r.numberOfChannels;t++)o[e]+=r.getChannelData(t)[e];return{audio:o,sampleRate:r.sampleRate}},encodeWAV:function(i){let r=arguments.length>1&&void 0!==arguments[1]?arguments[1]:3,o=arguments.length>2&&void 0!==arguments[2]?arguments[2]:16e3,n=arguments.length>3&&void 0!==arguments[3]?arguments[3]:1,a=arguments.length>4&&void 0!==arguments[4]?arguments[4]:32;var h=a/8,c=n*h,p=new ArrayBuffer(44+i.length*h),u=new DataView(p);return s(u,0,"RIFF"),u.setUint32(4,36+i.length*h,!0),s(u,8,"WAVE"),s(u,12,"fmt "),u.setUint32(16,16,!0),u.setUint16(20,r,!0),u.setUint16(22,n,!0),u.setUint32(24,o,!0),u.setUint32(28,o*c,!0),u.setUint16(32,c,!0),u.setUint16(34,a,!0),s(u,36,"data"),u.setUint32(40,i.length*h,!0),1===r?t(u,44,i):e(u,44,i),p}}})(),r})()));